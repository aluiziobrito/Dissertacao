}
resultados <- avaliar_modelo_com_amostras("caminho/para/amostras.shp", img, rpart_pred)
resultados <- avaliar_modelo_com_amostras("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart_pred)
resultados <- avaliar_modelo_com_amostras("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart_pred_values)
resultados <- avaliar_modelo_com_amostras("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred)
resultados <- avaliar_modelo_com_amostras("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred_values
print(resultados)
print(resultados)
# Função para avaliar o modelo com amostras de teste
avaliar_modelo_simples <- function(caminho_amostras, img, rpart_pred) {
# Carregar as amostras
amostras_aleatorias <- st_read(caminho_amostras)  # Para shapefiles
# Verificar se a coluna "Classe" está presente
if (!"Classe" %in% colnames(amostras_aleatorias)) {
stop("A coluna 'Classe' não foi encontrada nas amostras.")
}
# Transformar as amostras para o CRS do raster predito
amostras_aleatorias <- st_transform(amostras_aleatorias, crs(rpart_pred))
# Extrair os valores do raster predito nas localizações das amostras
valores_preditos <- raster::extract(rpart_pred, amostras_aleatorias)
# Obter os valores reais de classe das amostras
valores_reais <- amostras_aleatorias$Classe
# Calcular as métricas de desempenho
vp <- sum(valores_preditos == 1 & valores_reais == 1, na.rm = TRUE)
vn <- sum(valores_preditos == 2 & valores_reais == 2, na.rm = TRUE)
fp <- sum(valores_preditos == 1 & valores_reais == 2, na.rm = TRUE)
fn <- sum(valores_preditos == 2 & valores_reais == 1, na.rm = TRUE)
# Acurácia
ag <- (vp + vn) / (vp + vn + fp + fn)
# Sensibilidade
sensibilidade <- ifelse((vp + fn) == 0, 0, vp / (vp + fn))
# Precisão
precisao <- ifelse((vp + fp) == 0, 0, vp / (vp + fp))
# F1-Score
f1 <- ifelse((precisao + sensibilidade) == 0, 0, 2 * (precisao * sensibilidade) / (precisao + sensibilidade))
# Especificidade
especificidade <- ifelse((vn + fp) == 0, 0, vn / (vn + fp))
# MCC
mcc <- calcular_mcc(vp, vn, fp, fn)
# Retornar os resultados
resultados <- list(
Acuracia = ag,
Sensibilidade = sensibilidade,
Precisao = precisao,
F1 = f1,
Especificidade = especificidade,
Falsos_Positivos = fp,
Falsos_Negativos = fn,
MCC = mcc
)
return(resultados)
}
resultados <- avaliar_modelo_simples("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart_pred)
resultados <- avaliar_modelo_simples("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred)
print(resultados)
# Função para calcular o MCC
calcular_mcc <- function(vp, vn, fp, fn) {
numerador <- (vp * vn) - (fp * fn)
denominador <- sqrt((vp + fp) * (vp + fn) * (vn + fp) * (vn + fn))
if (denominador == 0) {
return(0)
}
mcc <- numerador / denominador
return(mcc)
}
# Avaliando o modelo com amostras aleatórias
avaliar_modelo <- function(caminho_amostras, img, rpart_pred) {
# Carregar as amostras aleatórias
amostras_aleatorias <- st_read(caminho_amostras)
# Verificar se a coluna "Classe" existe na camada
if (!"Classe" %in% colnames(amostras_aleatorias)) {
stop("A coluna 'Classe' não existe.")
}
# Transformar CRS das amostras
amostras_aleatorias <- st_transform(amostras_aleatorias, crs(rpart_pred))
# Extrair os valores do raster preditos pelo rpart
valores_preditos <- raster::extract(rpart_pred, amostras_aleatorias)
# Obter os valores da amostra
valores_reais <- amostras_aleatorias$Classe
# Calcular as métricas de desempenho
# Atenção aos números usado para as classes e altere se necessário, neste caso, 1 representa nuvens/sombras e 2 representa outras coberturas
vp <- sum(valores_preditos == 1 & valores_reais == 1, na.rm = TRUE)
vn <- sum(valores_preditos == 2 & valores_reais == 2, na.rm = TRUE)
fp <- sum(valores_preditos == 1 & valores_reais == 2, na.rm = TRUE)
fn <- sum(valores_preditos == 2 & valores_reais == 1, na.rm = TRUE)
# Acurácia Global
ag <- (vp + vn) / (vp + vn + fp + fn)
# Sensibilidade
sensibilidade <- ifelse((vp + fn) == 0, 0, vp / (vp + fn))
# Precisão
precisao <- ifelse((vp + fp) == 0, 0, vp / (vp + fp))
# F1-Score
f1 <- ifelse((precisao + sensibilidade) == 0, 0, 2 * (precisao * sensibilidade) / (precisao + sensibilidade))
# Especificidade
especificidade <- ifelse((vn + fp) == 0, 0, vn / (vn + fp))
# Matthew Correlation Coefficient
mcc <- calcular_mcc(vp, vn, fp, fn)
# Armazenar resultados em um data frame para os gráficos
df_mcc <- data.frame(Modelo = "Modelo Avaliado", MCC = mcc)
df_fp_fn <- data.frame(Modelo = "Modelo Avaliado", Falsos_Positivos = fp, Falsos_Negativos = fn)
# Função para gerar os gráficos
gerar_graficos <- function(df_mcc, df_fp_fn) {
# Gráfico para MCC
p1 <- ggplot(df_mcc, aes(x = Modelo, y = MCC, group = 1)) +
geom_line(color = "#FFA500", size = 1) +  # Cor laranja
geom_point(color = "#FFA500", size = 4) +
labs(title = "Comparação do MCC", x = "Modelo", y = "MCC") +
ylim(0, 1) +
theme_minimal(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5))
# Gráfico para FPs e FNs
p2 <- ggplot(df_fp_fn, aes(x = Modelo)) +
geom_line(aes(y = Falsos_Positivos, color = "Falsos Positivos"), size = 1) +
geom_point(aes(y = Falsos_Positivos, color = "Falsos Positivos"), size = 4) +
geom_line(aes(y = Falsos_Negativos, color = "Falsos Negativos"), size = 1) +
geom_point(aes(y = Falsos_Negativos, color = "Falsos Negativos"), size = 4) +
labs(title = "Comparação dos Falsos Positivos e Falsos Negativos", x = "Modelo", y = "Quantidade") +
scale_color_manual(name = "Métricas", values = c("Falsos Positivos" = "#4682B4", "Falsos Negativos" = "#B22222")) +
theme_minimal(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5))
# Combinar os gráficos
grid.arrange(p1, p2, ncol = 2)
}
# Gerar os gráficos
gerar_graficos(df_mcc, df_fp_fn)
# Resultados em uma lista
resultados <- list(
Acuracia = ag,
Sensibilidade = sensibilidade,
Precisao = precisao,
F1 = f1,
Especificidade = especificidade,
Falsos_Positivos = fp,
Falsos_Negativos = fn,
MCC = mcc
)
# Exibir os resultados um a um
for (nome in names(resultados)) {
cat(nome, ":", resultados[[nome]], "\n")
readline(prompt = "Pressione Enter para continuar...")
}
return(resultados)
}
resultados <- avaliar_modelo("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred
return(resultados)
resultados <- avaliar_modelo("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred)
library(ggplot2)
resultados <- avaliar_modelo("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred)
print(resultados)
# Função para calcular o MCC
calcular_mcc <- function(vp, vn, fp, fn) {
numerador <- (vp * vn) - (fp * fn)
denominador <- sqrt((vp + fp) * (vp + fn) * (vn + fp) * (vn + fn))
if (denominador == 0) {
return(0)
}
mcc <- numerador / denominador
return(mcc)
}
# Avaliando o modelo com amostras aleatórias
avaliar_modelo <- function(caminho_amostras, img, rpart_pred) {
# Carregar as amostras aleatórias
amostras_aleatorias <- st_read(caminho_amostras)
# Verificar se a coluna "Classe" existe na camada
if (!"Classe" %in% colnames(amostras_aleatorias)) {
stop("A coluna 'Classe' não existe.")
}
# Transformar CRS das amostras
amostras_aleatorias <- st_transform(amostras_aleatorias, crs(rpart_pred))
# Extrair os valores do raster preditos pelo rpart
valores_preditos <- raster::extract(rpart_pred, amostras_aleatorias)
# Obter os valores da amostra
valores_reais <- amostras_aleatorias$Classe
# Calcular as métricas de desempenho
# Atenção aos números usado para as classes e altere se necessário, neste caso, 1 representa nuvens/sombras e 2 representa outras coberturas
vp <- sum(valores_preditos == 1 & valores_reais == 1, na.rm = TRUE)
vn <- sum(valores_preditos == 2 & valores_reais == 2, na.rm = TRUE)
fp <- sum(valores_preditos == 1 & valores_reais == 2, na.rm = TRUE)
fn <- sum(valores_preditos == 2 & valores_reais == 1, na.rm = TRUE)
# Acurácia Global
ag <- (vp + vn) / (vp + vn + fp + fn)
# Sensibilidade
sensibilidade <- ifelse((vp + fn) == 0, 0, vp / (vp + fn))
# Precisão
precisao <- ifelse((vp + fp) == 0, 0, vp / (vp + fp))
# F1-Score
f1 <- ifelse((precisao + sensibilidade) == 0, 0, 2 * (precisao * sensibilidade) / (precisao + sensibilidade))
# Especificidade
especificidade <- ifelse((vn + fp) == 0, 0, vn / (vn + fp))
# Matthew Correlation Coefficient
mcc <- calcular_mcc(vp, vn, fp, fn)
# Armazenar resultados em um data frame para os gráficos
df_mcc <- data.frame(Modelo = "Modelo Avaliado", MCC = mcc)
df_fp_fn <- data.frame(Modelo = "Modelo Avaliado", Falsos_Positivos = fp, Falsos_Negativos = fn)
# Função para gerar os gráficos
gerar_graficos <- function(df_mcc, df_fp_fn) {
# Gráfico para MCC
p1 <- ggplot(df_mcc, aes(x = Modelo, y = MCC, group = 1)) +
geom_line(color = "#FFA500", size = 1) +  # Cor laranja
geom_point(color = "#FFA500", size = 4) +
labs(title = "Comparação do MCC", x = "Modelo", y = "MCC") +
ylim(0, 1) +
theme_minimal(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5))
# Gráfico para FPs e FNs
p2 <- ggplot(df_fp_fn, aes(x = Modelo)) +
geom_line(aes(y = Falsos_Positivos, color = "Falsos Positivos"), size = 1) +
geom_point(aes(y = Falsos_Positivos, color = "Falsos Positivos"), size = 4) +
geom_line(aes(y = Falsos_Negativos, color = "Falsos Negativos"), size = 1) +
geom_point(aes(y = Falsos_Negativos, color = "Falsos Negativos"), size = 4) +
labs(title = "Comparação dos Falsos Positivos e Falsos Negativos", x = "Modelo", y = "Quantidade") +
scale_color_manual(name = "Métricas", values = c("Falsos Positivos" = "#4682B4", "Falsos Negativos" = "#B22222")) +
theme_minimal(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5))
# Combinar os gráficos
grid.arrange(p1, p2, ncol = 2)
}
# Gerar os gráficos
gerar_graficos(df_mcc, df_fp_fn)
# Resultados em uma lista
resultados <- list(
Acuracia = ag,
Sensibilidade = sensibilidade,
Precisao = precisao,
F1 = f1,
Especificidade = especificidade,
Falsos_Positivos = fp,
Falsos_Negativos = fn,
MCC = mcc
)
# Exibir os resultados um a um
for (nome in names(resultados)) {
cat(nome, ":", resultados[[nome]], "\n")
readline(prompt = "Pressione Enter para continuar...")
}
return(resultados)
}
resultados <- avaliar_modelo("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred)
library(gridExtra)
# Função para calcular o MCC
calcular_mcc <- function(vp, vn, fp, fn) {
numerador <- (vp * vn) - (fp * fn)
denominador <- sqrt((vp + fp) * (vp + fn) * (vn + fp) * (vn + fn))
if (denominador == 0) {
return(0)
}
mcc <- numerador / denominador
return(mcc)
}
# Função para avaliar o modelo e gerar gráficos
avaliar_modelo <- function(caminho_amostras, img, rpart_pred) {
# Carregar as amostras aleatórias
amostras_aleatorias <- st_read(caminho_amostras)
# Verificar se a coluna "Classe" existe na camada
if (!"Classe" %in% colnames(amostras_aleatorias)) {
stop("A coluna 'Classe' não existe.")
}
# Transformar CRS das amostras
amostras_aleatorias <- st_transform(amostras_aleatorias, crs(rpart_pred))
# Extrair os valores do raster preditos pelo rpart
valores_preditos <- raster::extract(rpart_pred, amostras_aleatorias)
# Obter os valores da amostra
valores_reais <- amostras_aleatorias$Classe
# Calcular as métricas de desempenho
vp <- sum(valores_preditos == 1 & valores_reais == 1, na.rm = TRUE)
vn <- sum(valores_preditos == 2 & valores_reais == 2, na.rm = TRUE)
fp <- sum(valores_preditos == 1 & valores_reais == 2, na.rm = TRUE)
fn <- sum(valores_preditos == 2 & valores_reais == 1, na.rm = TRUE)
# Acurácia Global
ag <- (vp + vn) / (vp + vn + fp + fn)
# Sensibilidade
sensibilidade <- ifelse((vp + fn) == 0, 0, vp / (vp + fn))
# Precisão
precisao <- ifelse((vp + fp) == 0, 0, vp / (vp + fp))
# F1-Score
f1 <- ifelse((precisao + sensibilidade) == 0, 0, 2 * (precisao * sensibilidade) / (precisao + sensibilidade))
# Especificidade
especificidade <- ifelse((vn + fp) == 0, 0, vn / (vn + fp))
# Matthew Correlation Coefficient
mcc <- calcular_mcc(vp, vn, fp, fn)
# Armazenar resultados em um data frame para os gráficos
df_mcc <- data.frame(Modelo = "Modelo Avaliado", MCC = mcc)
df_fp_fn <- data.frame(Modelo = "Modelo Avaliado", Falsos_Positivos = fp, Falsos_Negativos = fn)
# Função para gerar os gráficos
gerar_graficos <- function(df_mcc, df_fp_fn) {
# Gráfico para MCC
p1 <- ggplot(df_mcc, aes(x = Modelo, y = MCC, group = 1)) +
geom_line(color = "#FFA500", size = 1) +  # Cor laranja
geom_point(color = "#FFA500", size = 4) +
labs(title = "Comparação do MCC", x = "Modelo", y = "MCC") +
ylim(0, 1) +
theme_minimal(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5))
# Gráfico para FPs e FNs
p2 <- ggplot(df_fp_fn, aes(x = Modelo)) +
geom_line(aes(y = Falsos_Positivos, color = "Falsos Positivos"), size = 1) +
geom_point(aes(y = Falsos_Positivos, color = "Falsos Positivos"), size = 4) +
geom_line(aes(y = Falsos_Negativos, color = "Falsos Negativos"), size = 1) +
geom_point(aes(y = Falsos_Negativos, color = "Falsos Negativos"), size = 4) +
labs(title = "Comparação dos Falsos Positivos e Falsos Negativos", x = "Modelo", y = "Quantidade") +
scale_color_manual(name = "Métricas", values = c("Falsos Positivos" = "#4682B4", "Falsos Negativos" = "#B22222")) +
theme_minimal(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5))
# Combinar os gráficos
grid.arrange(p1, p2, ncol = 2)
}
# Gerar os gráficos
gerar_graficos(df_mcc, df_fp_fn)
# Resultados em uma lista
resultados <- list(
Acuracia = ag,
Sensibilidade = sensibilidade,
Precisao = precisao,
F1 = f1,
Especificidade = especificidade,
Falsos_Positivos = fp,
Falsos_Negativos = fn,
MCC = mcc
)
# Exibir os resultados um a um
for (nome in names(resultados)) {
cat(nome, ":", resultados[[nome]], "\n")
readline(prompt = "Pressione Enter para continuar...")
}
return(resultados)
}
# Exemplo de uso
resultados <- avaliar_modelo("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred)
# Função para calcular o MCC
calcular_mcc <- function(vp, vn, fp, fn) {
numerador <- (vp * vn) - (fp * fn)
denominador <- sqrt((vp + fp) * (vp + fn) * (vn + fp) * (vn + fn))
if (denominador == 0) {
return(0)
}
mcc <- numerador / denominador
return(mcc)
}
# Avaliando o modelo com amostras aleatórias
avaliar_modelo <- function(caminho_amostras, img, rpart_pred) {
# Carregar as amostras aleatórias
amostras_aleatorias <- st_read(caminho_amostras)
# Verificar se a coluna "Classe" existe na camada
if (!"Classe" %in% colnames(amostras_aleatorias)) {
stop("A coluna 'Classe' não existe.")
}
# Transformar CRS das amostras
amostras_aleatorias <- st_transform(amostras_aleatorias, crs(rpart_pred))
# Extrair os valores do raster preditos pelo rpart
valores_preditos <- raster::extract(rpart_pred, amostras_aleatorias)
# Obter os valores da amostra
valores_reais <- amostras_aleatorias$Classe
# Calcular as métricas de desempenho
# Atenção aos números usado para as classes e altere se necessário, neste caso, 1 representa nuvens/sombras e 2 representa outras coberturas
vp <- sum(valores_preditos == 1 & valores_reais == 1, na.rm = TRUE)
vn <- sum(valores_preditos == 2 & valores_reais == 2, na.rm = TRUE)
fp <- sum(valores_preditos == 1 & valores_reais == 2, na.rm = TRUE)
fn <- sum(valores_preditos == 2 & valores_reais == 1, na.rm = TRUE)
# Acurácia Global
ag <- (vp + vn) / (vp + vn + fp + fn)
# Sensibilidade
sensibilidade <- ifelse((vp + fn) == 0, 0, vp / (vp + fn))
# Precisão
precisao <- ifelse((vp + fp) == 0, 0, vp / (vp + fp))
# F1-Score
f1 <- ifelse((precisao + sensibilidade) == 0, 0, 2 * (precisao * sensibilidade) / (precisao + sensibilidade))
# Especificidade
especificidade <- ifelse((vn + fp) == 0, 0, vn / (vn + fp))
# Matthew Correlation Coefficient
mcc <- calcular_mcc(vp, vn, fp, fn)
resultados <- list(
Acuracia = ag,
Sensibilidade = sensibilidade,
Precisao = precisao,
F1 = f1,
Especificidade = especificidade,
Falsos_Positivos = fp,
Falsos_Negativos = fn,
MCC = mcc
)
return(resultados)
}
resultados <- avaliar_modelo("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred)
print(resultados)
# Plotar todas as métricas
p <- ggplot(df_metricas, aes(x = Modelo)) +
geom_point(aes(y = MCC, color = "MCC"), size = 4) +
geom_point(aes(y = Acuracia, color = "Acurácia"), size = 4) +
geom_point(aes(y = Sensibilidade, color = "Sensibilidade"), size = 4) +
geom_point(aes(y = Precisao, color = "Precisão"), size = 4) +
geom_point(aes(y = F1, color = "F1"), size = 4) +
geom_line(aes(y = Falsos_Positivos / max(Falsos_Positivos), color = "Falsos Positivos"), size = 1, linetype = "dashed") +
geom_line(aes(y = Falsos_Negativos / max(Falsos_Negativos), color = "Falsos Negativos"), size = 1, linetype = "dashed") +
scale_color_manual(name = "Métricas", values = c(
"MCC" = "#FFA500",
"Acurácia" = "#4682B4",
"Sensibilidade" = "#B22222",
"Precisão" = "#32CD32",
"F1" = "#8A2BE2",
"Falsos Positivos" = "#FFD700",
"Falsos Negativos" = "#FF4500"
)) +
labs(title = "Comparação de Métricas de Desempenho do Modelo", x = "Modelo", y = "Valor da Métrica") +
theme_minimal(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5))
# Plotar todas as métricas
p <- ggplot(resultados, aes(x = Modelo)) +
geom_point(aes(y = MCC, color = "MCC"), size = 4) +
geom_point(aes(y = Acuracia, color = "Acurácia"), size = 4) +
geom_point(aes(y = Sensibilidade, color = "Sensibilidade"), size = 4) +
geom_point(aes(y = Precisao, color = "Precisão"), size = 4) +
geom_point(aes(y = F1, color = "F1"), size = 4) +
geom_line(aes(y = Falsos_Positivos / max(Falsos_Positivos), color = "Falsos Positivos"), size = 1, linetype = "dashed") +
geom_line(aes(y = Falsos_Negativos / max(Falsos_Negativos), color = "Falsos Negativos"), size = 1, linetype = "dashed") +
scale_color_manual(name = "Métricas", values = c(
"MCC" = "#FFA500",
"Acurácia" = "#4682B4",
"Sensibilidade" = "#B22222",
"Precisão" = "#32CD32",
"F1" = "#8A2BE2",
"Falsos Positivos" = "#FFD700",
"Falsos Negativos" = "#FF4500"
)) +
labs(title = "Comparação de Métricas de Desempenho do Modelo", x = "Modelo", y = "Valor da Métrica") +
theme_minimal(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5))
gerar_grafico_completo <- function(df_metricas) {
# Verificar se o pacote ggplot2 está instalado
if (!requireNamespace("ggplot2", quietly = TRUE)) {
stop("O pacote 'ggplot2' não está instalado. Por favor, instale-o antes de prosseguir.")
}
# Plotar todas as métricas
p <- ggplot(df_metricas, aes(x = Modelo)) +
geom_point(aes(y = MCC, color = "MCC"), size = 4) +
geom_point(aes(y = Acuracia, color = "Acurácia"), size = 4) +
geom_point(aes(y = Sensibilidade, color = "Sensibilidade"), size = 4) +
geom_point(aes(y = Precisao, color = "Precisão"), size = 4) +
geom_point(aes(y = F1, color = "F1"), size = 4) +
geom_line(aes(y = Falsos_Positivos / max(Falsos_Positivos), color = "Falsos Positivos"), size = 1, linetype = "dashed") +
geom_line(aes(y = Falsos_Negativos / max(Falsos_Negativos), color = "Falsos Negativos"), size = 1, linetype = "dashed") +
scale_color_manual(name = "Métricas", values = c(
"MCC" = "#FFA500",
"Acurácia" = "#4682B4",
"Sensibilidade" = "#B22222",
"Precisão" = "#32CD32",
"F1" = "#8A2BE2",
"Falsos Positivos" = "#FFD700",
"Falsos Negativos" = "#FF4500"
)) +
labs(title = "Comparação de Métricas de Desempenho do Modelo", x = "Modelo", y = "Valor da Métrica") +
theme_minimal(base_size = 15) +
theme(plot.title = element_text(hjust = 0.5))
# Mostrar o gráfico
print(p)
}
print(p)
# Função para calcular o MCC
calcular_mcc <- function(vp, vn, fp, fn) {
numerador <- (vp * vn) - (fp * fn)
denominador <- sqrt((vp + fp) * (vp + fn) * (vn + fp) * (vn + fn))
if (denominador == 0) {
return(0)
}
mcc <- numerador / denominador
return(mcc)
}
# Avaliando o modelo com amostras aleatórias
avaliar_modelo <- function(caminho_amostras, img, rpart_pred) {
# Carregar as amostras aleatórias
amostras_aleatorias <- st_read(caminho_amostras)
# Verificar se a coluna "Classe" existe na camada
if (!"Classe" %in% colnames(amostras_aleatorias)) {
stop("A coluna 'Classe' não existe.")
}
# Transformar CRS das amostras
amostras_aleatorias <- st_transform(amostras_aleatorias, crs(rpart_pred))
# Extrair os valores do raster preditos pelo rpart
valores_preditos <- raster::extract(rpart_pred, amostras_aleatorias)
# Obter os valores da amostra
valores_reais <- amostras_aleatorias$Classe
# Calcular as métricas de desempenho
# Atenção aos números usado para as classes e altere se necessário, neste caso, 1 representa nuvens/sombras e 2 representa outras coberturas
vp <- sum(valores_preditos == 1 & valores_reais == 1, na.rm = TRUE)
vn <- sum(valores_preditos == 2 & valores_reais == 2, na.rm = TRUE)
fp <- sum(valores_preditos == 1 & valores_reais == 2, na.rm = TRUE)
fn <- sum(valores_preditos == 2 & valores_reais == 1, na.rm = TRUE)
# Acurácia Global
ag <- (vp + vn) / (vp + vn + fp + fn)
# Sensibilidade
sensibilidade <- ifelse((vp + fn) == 0, 0, vp / (vp + fn))
# Precisão
precisao <- ifelse((vp + fp) == 0, 0, vp / (vp + fp))
# F1-Score
f1 <- ifelse((precisao + sensibilidade) == 0, 0, 2 * (precisao * sensibilidade) / (precisao + sensibilidade))
# Especificidade
especificidade <- ifelse((vn + fp) == 0, 0, vn / (vn + fp))
# Matthew Correlation Coefficient
mcc <- calcular_mcc(vp, vn, fp, fn)
resultados <- list(
Acuracia = ag,
Sensibilidade = sensibilidade,
Precisao = precisao,
F1 = f1,
Especificidade = especificidade,
Falsos_Positivos = fp,
Falsos_Negativos = fn,
MCC = mcc
)
return(resultados)
}
resultados <- avaliar_modelo("D:\\Dissertação\\Nuvens e Sombras\\Teste\\pontos_selecionados.shp", img, rpart.pred)
print(resultados)
